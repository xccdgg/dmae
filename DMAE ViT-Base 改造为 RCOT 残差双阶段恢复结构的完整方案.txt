DMAE ViT-Base 改造为 RCOT 残差双阶段恢复结构的完整方案
RCOT参考链接https://github.com/xl-tang3/RCOT?tab=readme-ov-file
背景与目标
Denoising  Masked  Autoencoder  (DMAE)  是一种结合图像掩码和添加噪声的自监督视觉Transformer模型
1。其编码器使用ViT-Base架构，经过预训练能够从被噪声腐蚀并随机掩码的图像重建原始清晰图像，从而学
到鲁棒的视觉特征。为进一步提升图像恢复任务（如去噪）的效果，我们希望引入       Residual-Conditioned Optimal  Transport  (RCOT)  框架中的“两阶段残差条件恢复”思想，将DMAE模型改造成残差二阶段恢复结 构。
RCOT框架的核心是在第一次粗恢复后，引入一个残差条件模块对第二次精细恢复进行指导 2。具体来说，第  一阶段模型输出初步重建结果，再计算其与原图的差（残差），通过残差编码器将残差映射为嵌入向量；第二   阶段模型将该残差嵌入作为条件，对第一阶段结果进行细化，从而更好地恢复图像细节和结构 3    4。本方案 的目标包括：
• 保留DMAE预训练架构与权重：沿用DMAE的ViT-Base编码器和解码器结构及其预训练参数，充分利用 其学到的强大表征能力。
• 引入残差二阶段机制：在第一阶段得到初步重建图像 $\hat{x}$ 后，计算残差 $r = x_{\text{gt}} - \hat{x}  $（训练时使用真实清晰图像 $x_{\text{gt}}$；推理时可用输入退化图像 $x_{\text{noisy}}$ 与 $\hat{x}$ 的差近似残差）。设计一个轻量级残差编码器将 $r$ 提取为残差嵌入 $e$，作为第二阶段恢复的条件。
• 条件化精细解码器：在第二阶段，引入条件解码器（可通过FiLM等机制）将残差嵌入 $e$ 融合进解码过 程，产生精细恢复的输出 $\hat{x}_{refined}$。这样可提升复原精度，增强结构细节的保真度 3   。
• 代码实现：给出PyTorch代码，包括残差编码器、FiLM条件化模块的定义，前向传播流程的修改，以及 如何加载DMAE预训练权重等。
• 训练适配：确保该双阶段架构适用于图像恢复任务（如去噪），可在ImageNet、CIFAR-10等数据集上 验证。在一张RTX 3090上可进行微调训练，尽量减少新增参数和显存开销。
接下来，我们将详细介绍该方案的架构设计、模块实现、前向与损失设计，并提供完整代码和微调训练建议。

架构设计与流程
下面给出了改造后模型的总体架构流程图。第一阶段沿用DMAE的编码器和解码器得到初步结果，第二阶段使用 残差编码器和条件解码器进一步细化输出：



架构说明：
• ViT-Base编码器：  使用DMAE预训练好的ViT-Base编码器作为第一阶段的编码器 1。输入为退化的图 像（如含噪图像或低质图像），经过Patch分块和线性嵌入，加上位置编码后送入Transformer编码器， 输出一系列图像patch的特征表示 $z\in\mathbb{R}^{N\times D}$（其中 $N$ 是patch数，$D$是嵌入 维度，如768）。重要：保留编码器权重以利用其学习到的表示能力，不改变其结构和参数规模。

• 第一阶段解码器      (Decoder1)：      采用DMAE自带的图像重建解码器结构（Transformer解码器）。 Decoder1将编码器输出的latent tokens $z$ 解码为重建图像 $\hat{x}$。在DMAE预训练中，该解码器 已学习在缺失和噪声条件下重构图像的能力，我们将在此基础上进行微调。第一阶段输出的    $\hat{x}$ 是对输入退化图像的初步恢复，其整体轮廓和颜色应接近原图，但可能缺乏细节或有余留误差。

• 残差计算与残差编码器： 取得初步结果后，计算残差图像 $r = x_{\text{gt}} - \hat{x}$。在有监督训练 时，直接使用真实清晰图像 $x_{\text{gt}}$ 计算；推理时无真实 $x_{\text{gt}}$，可用原始退化输入近 似地计算 $r \approx x_{\text{noisy}} - \hat{x}$，认为$\hat{x}$中未消除的部分近似对应残余噪声或细 节偏差。残差 $r$ 保留了第一阶段未恢复好的细节和噪声模式，是退化特定的关键信息。我们引入一个 残差编码器 (Residual Encoder)，将 $r$ 编码为一个残差嵌入向量 $e$ 4。为了减少额外开销，残差 编码器可以设计得较轻量，例如一个小型卷积网络或Transformer编码器。它接受残差图像  (通道维度3) 输出一个低维向量 $e\in\mathbb{R}^{D_e}$（可选定 $D_e = D$ 与主编码器维度相同以便融合）。这 个 $e$ 提炼了残差中的结构细节和噪声模式，作为条件信息供第二阶段使用。

• 第二阶段条件解码器    (Decoder2)：    第二阶段的解码器结构与第一阶段类似，也是Transformer解码 器，但在每一层引入条件调制机制，使之受残差嵌入 $e$ 的信息引导 4。直观来说，   Decoder2基于编 码器的同一组latent特征    $z$（因为输入图像内容没有变），通过融合残差嵌入，有条件地重建图像。 在RCOT原论文中采用了跨阶段特征融合等手段引入残差条件 5   ；在本方案中，我们采用FiLM
(Feature-wise     Linear      Modulation)      模块在Transformer解码器中融合条件。具体做法是：在 Decoder2的每个Transformer层，利用残差嵌入       $e$       生成对该层隐藏特征的缩放和偏移系数（$ \gamma$  和   $\beta$），对特征逐维进行仿射变换，实现条件调制。通过这种方式，残差中的关键信 息可以影响第二阶段解码器的每一层，使输出$\hat{x}_{refined}$更加接近原图，改善细节纹理和结构   保真度 3   。

参数与效率考虑：为控制新增参数和显存占用，Residual Encoder可采用小型网络（例如3层卷积＋池化）输出 一个与ViT嵌入等维的向量  $e$。FiLM模块每层仅增加两组线性参数（$\gamma,\beta$生成器），参数量非常 小。第二阶段Decoder2可以选择共享第一阶段Decoder1的大部分结构和参数，通过FiLM实现差异（例如直接   复制Decoder1权重作为初始化），从而避免参数翻倍。即使不共享，Decoder2结构与Decoder1相同
（Transformer层数相同），其参数量相对ViT-Base编码器也较小。在实际实现中，我们可以：1）加载DMAE 预训练的编码器和解码器权重；2）将Decoder1权重复制给Decoder2作为初始值（新增的FiLM参数随机初始
化）；3）在训练时主要调整残差编码器和FiLM模块参数，必要时微调两个解码器和编码器。整个模型可以在单 卡RTX 3090（24GB）上训练，新增模块轻量不会显著增加显存负担。

模块定义与接口说明
为实现上述架构，我们需要增添以下模块，并定义它们的接口：

• ResidualEncoder 模块： 接受残差图像 $r$ 作为输入，输出残差嵌入向量 $e$。可以使用卷积网络或 Transformer。这里建议使用小型卷积网络以兼顾效率：
• 输入：残差图像张量，形状  [B, 3, H, W] （与原图尺寸相同，B为批大小）。
• 输出：残差嵌入向量，形状  [B, D_e] 。我们通常设 $D_e = D$（ViT编码器的嵌入维度，如768），便 于后续融合。如果不同也可在FiLM中增加投影层。
• 实现：例如3层卷积每层步幅2进行下采样，将图像压缩，最后全局池化并全连接得到向量。附加非线性 激活。如：

◦ Conv(3→32, k=3, s=2) + BN + ReLU
◦ Conv(32→64, k=3, s=2) + BN + ReLU
◦ Conv(64→ 128, k=3, s=2) + BN + ReLU
◦ Global Average Pool (输出尺寸128)
◦ 全连接 FC(128 → D) + GELU 激活，得到 $e`向量.
• FiLMBlock 模块： 实现特征逐维的线性调制。给定残差嵌入 $e$，生成对应尺度和偏移，用于调节任意 一层的特征:

• 输入：条件向量 $e （形状 [B, D_e] ）和待调制特征张量（形状可以是 [B, N, D] 例如Transformer层的 输出，或 [B, D]`用于全局特征）。
• 输出：与输入特征形状相同的张量，每个通道（特征维度）乘以$\gamma$加上$\beta$偏移，其中$   \gamma,\beta$均由$e$经过线性层映射得到      。FiLM公式：$\text{FiLM}(x_{ij} | e) = \gamma_j(e) \cdot x_{ij} + \beta_j(e)$，其中$j$索引特征维度。
• 实现：包含两个全连接层：$\gamma = \text{Linear}(e)$，$\beta = \text{Linear}(e)$，输出维度均为 待调制特征的通道数$D$。将$\gamma,\beta$扩维后与特征逐元素相乘/相加。

• ConditionalDecoder  模块：  第二阶段的Transformer解码器，其结构与DMAE原本解码器类似，但支 持额外的条件输入:

• 接口：可以设计为  forward(latent_tokens,  cond_embed) ，其中  latent_tokens 是编码器输出的 patch序列表示（形状  [B,  N,  D] ）， cond_embed 是残差嵌入向量$e$（形状  [B,  D_e] ）。
• 内部由多层Transformer解码块组成。每个解码块类似标准Transformer Block（自注意力+前馈网
络），但在前馈结束或整个Block输出处，插入FiLM调制步骤。即  x  = x + \text{MSA}(\text{LN}
_1(x)); x = x + \text{FFN}(\text{LN}_2(x)); x = \text{FiLM}(e, x) 。这样每个Block都使用条 件向量$e$调整输出特征。
• 解码器首层需要接收编码器的输出tokens。由于我们未使用掩码重建（针对去噪任务通常输入完整图
像），Decoder2可以直接以编码器输出$z$作为输入（或可选再加位置编码）。注意：如果DMAE原解  码器在预训练时使用了mask token填充，这里在微调时可令所有patch作为可见，从而Decoder正常工 作。
• 解码器最后输出每个patch的重建表示，需要映射回图像像素：通常MAE解码器使用一个linear投影将每 个patch的表示（维度$D$）映射为该patch的像素值（patch_sizepatch_size3）。例如ViT-Base默认    16x16补丁，则每个token需输出$16163=768$维并reshape回图像块。ConditionalDecoder可沿用这   种做法：在最后一层后接一个Linear层（称为 patch_predictor ），将每个token特征投影为像素块，
并重组为图像。
• 输出：重建的精细图像 $\hat{x}_{refined}$，形状与输入图像相同

• TwoStageDMAE 整体模型： 将上述模块组装：

• 属性包含： encoder （ViT编码器）， decoder1 （第一阶段解码器）， decoder2 （第二阶段条件解码 器）， res_encoder （残差编码器）。
• 前向 ( forward(x_noisy, x_clean=None) )：执行顺序为： z = encoder(x_noisy)  ； x_hat =
decoder1(z) ；计算残差  r = x_clean  -  x_hat （训练有$x_clean$时）或 r = x_noisy  - x_hat （推 理时）； e =  res_encoder(r)  ； x_refined = decoder2(z, e) 。返回 x_hat 和 x_refined 。这种设 计在训练时利用真实残差指导，但在推理时也能根据自身估计的残差进行第二次恢复。
• 预训练权重加载：使用DMAE提供的预训练模型参数初始化 encoder 和 decoder1 。若 decoder2 结构 与 decoder1 相同，可将 decoder1 的权重复制给 decoder2 作为初始化（然后再增加FiLM层参数）。 残差编码器和FiLM层的新参数随机初始化。
以上接口设计确保模块间尺寸匹配：例如ViT-Base编码器和解码器通常$D=768$，残差编码器输出同维度768的 $e$，FiLM映射$e$到768维用于解码器层调制。
前向传播与损失函数设计
前向传播流程： 按上述TwoStageDMAE模型的forward步骤执行。第一阶段得到  $\hat{x}$  后即可计算残差并 嵌入，紧接着条件解码器生成   $\hat{x}_{refined}$。需要注意在训练和推理时残差计算的差异，但对网络结构 无影响。
损失函数设计：  为训练该两阶段模型，我们可以对两个阶段的输出均施加监督损失，以稳定训练并确保第一阶 段不过度退化：
• 第一阶段损失 $L_{\text{stage1}}$： 计算初步输出 $\hat{x}$ 与目标清晰图像 $x_{\text{gt}}$ 之间的 差异损失，例如L2均方误差 (MSE) 或 L1损失。公式如 $L_1 = | \hat{x} - x_{\text{gt}}|_2^2$ (或 L1范 数)。

• 第二阶段损失 $L_{\text{stage2}}$： 计算精细输出 $\hat{x}{refined}$ 与 $x$ 之间的误差。同样可用 MSE或L1。由于第二阶段输出预期更接近真值，可赋予该损失更大的权重。}

• 总损失 $L_{\text{total}}$： 综合两阶段损失。简单加权例如：$L_{\text{total}} = L_{\text{stage2}} + \lambda  \cdot  L_{\text{stage1}}$，其中$\lambda<1$（如0.5） 以鼓励模型更关注精细输出的优化， 同时保证第一阶段不过度偏离合理初始重建。也可以仅对第二阶段输出计算主要损失，把第一阶段作为   辅助输出（辅助损失权重较低）。

此外，可根据需要添加感知损失（如VGG感知差异）或对抗损失（GAN）提高感观质量，不过这些属于进阶改 动，基础方案中主要采用像素级重建损失。RCOT论文中通过最优传输建模还引入了Fourier域的损失和对抗训 练 6，但在我们的实现中，可先采用简单MSE训练，再视情况融入感知/对抗损失提升细节。
前向细节注意： - 残差的使用： 训练时严禁将真实$x_{\text{gt}}$信息渗透到第二阶段除通过残差途径，因此我 们的设计是先用$\hat{x}$计算残差，再编码为$e$供第二阶段，整个过程是可微分的，允许残差编码器和解码
器共同学习如何利用残差。推理时因为没有$x_{\text{gt}}$，用$x_{\text{noisy}}-\hat{x}$近似残差，模型已学   会从这种近似残差提取有用信息来改进输出。 - Mask机制： DMAE预训练时有随机mask，但在有监督微调去噪 时我们通常不再掩盖输入（直接用完整带噪图像）。因此Decoder在微调时相当于全patch可见的情况。实践
中，可以在forward时跳过mask采样，直接将编码器输出$z$（长度为全部patch数）输入Decoder。这对预训 练模型不是问题，但要确保位置编码对齐完整图像。在我们的代码实现中，会直接使用编码器输出tokens馈入 Decoder。

PyTorch 实现代码
下面给出上述架构的PyTorch示例实现。代码中包括：ResidualEncoder、FiLMBlock、
ConditionalTransformerBlock、ConditionalDecoder模块，以及组合整体的TwoStageDMAE模型。为简洁起 见，我们假设已有 ViTEncoder 和 Decoder1 模块（来自预训练DMAE）可以直接加载，并侧重展示新增加模块 和修改的部分。

import torch
import torch.nn as nn
class ResidualEncoder(nn.Module):
"""将残差图像编码为残差嵌入向量的编码器。"""
def __init___(self, in_channels=3, embed_dim=768):
super().__init___()
# 三层卷积下采样
self.conv1 =  nn.Conv2d(in_channels, 32,  kernel_size=3,  stride=2,  padding=1) self.bn1     =  nn.BatchNorm2d(32)
self.conv2 =  nn.Conv2d(32,  64,  kernel_size=3,  stride=2,  padding=1)
self.bn2     =  nn.BatchNorm2d(64)
self.conv3 =  nn.Conv2d(64,  128,  kernel_size=3,  stride=2,  padding=1)
self.bn3     =  nn.BatchNorm2d(128)
# 全局平均池化 + 全连接得到残差嵌入
self.pool   =  nn.AdaptiveAvgPool2d((1,1))
self.fc       =  nn.Linear(128,  embed_dim)
self.act     =  nn.GELU()
def forward(self,  r):
"""
输入: r形状 [B, 3, H, W]（残差图像）
输出: e形状 [B, embed_dim]（残差嵌入向量）
"""
x = torch.relu(self.bn1(self.conv1(r)))
x = torch.relu(self.bn2(self.conv2(x)))
x = torch.relu(self.bn3(self.conv3(x)))
# 池化并展平
x = self.pool(x).view(x.size(0), -1)     # [B, 128]
e = self.act(self.fc(x))                        # [B, embed_dim]
return e
class FiLMBlock(nn.Module):
"""Feature-wise Linear Modulation：从条件向量生成每层特征的缩放和偏置。"""
def __init___(self, cond_dim, feat_dim):
super().__init___()
self.gamma_fc =  nn.Linear(cond_dim, feat_dim)
self.beta_fc   =  nn.Linear(cond_dim,  feat_dim)
def forward(self, cond, features):
"""
cond: 条件嵌入向量 e，形状 [B, cond_dim]
features: 待调制特征, 形状 [B, N, feat_dim] 或 [B, feat_dim]
返回: 调制后的特征张量，形状与features相同
"""

# 计算FiLM的gamma和beta参数
gamma = self.gamma_fc(cond)   # [B, feat_dim]
beta   = self.beta_fc(cond)     # [B, feat_dim]
# 若 features 为 [B, N, D]，扩展gamma, beta后逐token应用
if features.dim() == 3:
gamma = gamma.unsqueeze(1)   # [B, 1, D]
beta   =  beta.unsqueeze(1)     # [B, 1, D]
return features  * gamma +  beta
class ConditionalTransformerBlock(nn.Module):
"""
带条件FiLM调制的Transformer解码块，包含自注意力、前馈网络和FiLM。
"""
def __init___(self, embed_dim,  num_heads,  mlp_ratio=4.0, cond_dim=None):
super().__init___()
self.embed_dim = embed_dim
cond_dim = cond_dim  if cond_dim  is  not  None  else  embed_dim
# LayerNorm层
self.norm1 =  nn.LayerNorm(embed_dim)
self.norm2 =  nn.LayerNorm(embed_dim)
# 多头自注意力（这里batch_first=True使输入输出为[B, N, D]）
self.attn =  nn.MultiheadAttention(embed_dim,  num_heads,  batch_first=True)
# 前馈网络 (两层全连接)
hidden_dim = int(embed_dim *  mlp_ratio)
self.ffn =  nn.Sequential(
nn.Linear(embed_dim,  hidden_dim),
nn.GELU(),
nn.Linear(hidden_dim, embed_dim)
)
# FiLM调制模块
self.film =  FiLMBlock(cond_dim, embed_dim) def forward(self, x, cond=None):
"""
x: 上一层的特征 [B, N, embed_dim]
cond: 条件嵌入向量 e [B, cond_dim], 可为None表示无条件
"""
# 自注意力子层 + 残差连接
attn_out, _ = self.attn(self.norm1(x), self.norm1(x), self.norm1(x))
x = x +  attn_out
# 前馈子层 + 残差连接
ffn_out = self.ffn(self.norm2(x))
x = x + ffn_out
# 条件调制 (若提供了cond)
if cond  is  not  None:
x = self.film(cond, x)
return x
class ConditionalDecoder(nn.Module):
"""
第二阶段条件解码器，与DMAE解码器结构相同，但融合残差嵌入进行调制。
"""

def __init___(self, embed_dim=768,  num_layers=8,  num_heads=8,  mlp_ratio=4.0, cond_dim=None,  patch_size=16,  image_size=224):
super().__init___()
self.embed_dim = embed_dim
self.num_layers =  num_layers
# 位置编码 (假设需要，长度为每张图像的patch数目)
num_patches =  (image_size //  patch_size)  ** 2
self.pos_embed =  nn.Parameter(torch.zeros(1,  num_patches, embed_dim))
# Transformer解码块列表
self.blocks =  nn.ModuleList([
ConditionalTransformerBlock(embed_dim,  num_heads,  mlp_ratio, cond_dim) for _ in  range(num_layers)
])
self.norm =  nn.LayerNorm(embed_dim)
# 将每个token映射回patch像素的投影层
self.patch_size =  patch_size
self.out_proj =  nn.Linear(embed_dim,  patch_size*patch_size*3) def forward(self,  latent_tokens, cond):
"""
latent_tokens: 来自Encoder的patch特征 [B, N, embed_dim]
cond: 残差嵌入向量 e [B, cond_dim]
输出: 重建图像 [B, 3, H, W]
"""
# 加入位置编码
x =  latent_tokens + self.pos_embed[:,  :latent_tokens.size(1), :]
# 逐层Transformer解码，融合cond
for  block  in self.blocks:
x =  block(x,  cond)
x = self.norm(x)   # [B, N, D]
# 投影每个token为像素值并重组为图像
patch_pixels = self.out_proj(x)   # [B, N, patch_size*patch_size*3]
B,  N,  patch_dim  =  patch_pixels.shape
# 计算每边patch数量（假设图像为方形）
patches_per_side =  int(N ** 0.5)
# 重塑为[B, 3, H, W]
out =  patch_pixels.view(B,  patches_per_side,  patches_per_side,
self.patch_size, self.patch_size, 3)
# 变换维度顺序，将patch网格拼回图像
out = out.permute(0, 5,  1, 3, 2, 4).contiguous()
out_image = out.view(B, 3,  patches_per_side * self.patch_size,  patches_per_side * self.patch_size)
return out_image
class TwoStageDMAE(nn.Module):
"""
将编码器、第一阶段解码器、残差编码器、第二阶段解码器组合的完整两阶段模型。
"""
def __init___(self, encoder, decoder1, decoder2,  res_encoder):
super().__init___()
# 预训练ViT编码器 (DMAE) # 预训练解码器

self.decoder2 = decoder2       # 条件解码器 (复制结构, 带FiLM)
self.res_encoder =  res_encoder   # 残差编码器
def forward(self, x_noisy, x_clean=None):
"""
x_noisy: 退化输入图像 [B, 3, H, W]
x_clean: 对应清晰图像(训练时提供，用于计算残差；推理时可为None)
返回: (x_hat, x_refined) 分别为初步重建和精细重建图像
"""
# 第一阶段编码和解码
z = self.encoder(x_noisy)                     # 编码器输出 [B, N, D]
x_hat = self.decoder1(z)                       # 初步重建 [B, 3, H, W]
# 计算残差 (训练阶段用真实残差, 推理阶段用近似残差)
if x_clean  is  not  None:
r = x_clean - x_hat
else:
r = x_noisy - x_hat
# 残差编码为嵌入向量
e = self.res_encoder(r)                       # [B, D_e]
# 第二阶段条件解码
x_refined = self.decoder2(z, e)          # 精细重建 [B, 3, H, W]
return x_hat, x_refined
# ===== 使用预训练权重初始化 =====
# （假设已有预训练的 DMAE encoder 和 decoder1 权重文件或对象）
encoder = VitBaseEncoderPretrained(...)     # 预训练ViT-Base编码器实例（示例，占位）
decoder1 =  DMAEDecoderPretrained(...)         # 预训练DMAE解码器实例（示例，占位）
# 创建残差编码器和条件解码器
res_encoder =  ResidualEncoder(in_channels=3,  embed_dim=768)
decoder2 = ConditionalDecoder(embed_dim=768,  num_layers=decoder1.num_layers, num_heads=decoder1.num_heads, cond_dim=768,
patch_size=16,  image_size=224)
# 初始化decoder2权重与decoder1相同（除FiLM外）
decoder2.load_state_dict(decoder1.state_dict(), strict=False)
# 严格=False，因为decoder2多了FiLM参数和pos_embed/out_proj等可能名称不同，需要对齐 # 可以额外对齐参数：如将decoder1的pos_embed复制给decoder2.pos_embed等，手工赋值  # FiLM层参数因预训练无对应，可保持随机初始化
# 将各模块组装成完整模型
model = TwoStageDMAE(encoder, decoder1, decoder2,  res_encoder)

上述代码片段中：

• ResidualEncoder：3层卷积+池化输出残差嵌入 e 。
• FiLMBlock：用两层全连接从条件向量产生$\gamma,\beta$并应用到特征。
• ConditionalTransformerBlock：在标准Transformer Block的基础上，增加了FiLM调制（通过 self.film(cond, x) ）。
• ConditionalDecoder：构建多个ConditionalTransformerBlock，并在最后通过 out_proj 将token特 征转为像素块，拼接还原图像。我们添加了 pos_embed 参数用于位置编码（初始化为0这里只是占位说  明，可用预训练解码器的pos_embed初始化）。
• TwoStageDMAE：封装整体前向逻辑。注意 decoder1(z) 输出的是图像，因此我们假设 Decoder1 内 部已经做了patch投影重组（如上面的ConditionalDecoder的 out_proj 逻辑）。如果 Decoder1 输出 的是patch重建值，也可类似处理。

最后部分展示了如何加载预训练权重： encoder 和 decoder1 来自DMAE预训练模型。 decoder2 按照
decoder1 的结构初始化，并拷贝其权重（使用 strict=False 加载，以忽略不存在的FiLM相关参数）。由于
FiLM参数没有预训练对应，需要随机初始化。可以进一步复制 decoder1 的position  embedding和输出投影权 重到 decoder2 （如果名称不同需要手动赋值）。完成初始化后，将模块组成TwoStageDMAE模型。
以上代码为示例，各部分实际可根据DMAE实现有所调整，例如直接使用DMAE开源代码中的类。关键是展示如 何插入残差编码器和FiLM模块，修改前向传播流程。
微调训练建议
1. 分阶段训练 vs 端到端训练：

• 阶段一（冻结基础模型）：  建议首先冻结DMAE的编码器和第一阶段解码器，仅训练新加入的残差编码 器和第二阶段解码器（包括FiLM参数）。因为预训练模型已经能提供一个较好初始重建，这一步训练的  目的在于学习如何根据残差进行细化。在此阶段，可使用较高学习率（如$1e{-3}$-$1e{-4}$）针对新增   模块进行训练。这样既保证第一阶段输出保持稳定，又快速收敛残差相关模块。

• 阶段二（联合微调）：     在阶段一收敛后，可以解冻全部模型参数，进行端到端微调。这使得编码器和 Decoder1可以根据最终目标稍作调整，提高整体性能。此时应降低学习率（如$1e{-5}$-$5e{-5}$），以 免破坏预训练权重。也可对预训练部分使用更低lr、新模块使用较高lr（通过分层优化器设置）。联合微 调可以进一步提升第一阶段输出质量，从而减轻第二阶段负担。

若训练数据足够、策略稳健，也可以选择端到端一次性训练，即从一开始同时训练所有模块。在这种情况下建  议采用分组学习率：预训练部分使用小lr，新模块用较大lr，并适当权衡两阶段损失，确保第一阶段不会被训练 初期的随机残差扰动过度破坏。
2. 批大小与显存： ViT-Base编码器对显存要求较高。一张RTX 3090 (24GB)上，224×224图像可尝试批大小32 左右；CIFAR-10分辨率小（32×32）则可更大批次。两阶段模型比单阶段多了一次解码器前向，但解码器参数  相对不算巨大。若显存紧张，可减少批大小或使用梯度累计技术等。训练时可启用混合精度  (FP16/AMP)  来降 低显存占用和加速。

3. 损失权重与调优： 建议初始设置$\lambda \approx 0.5$（即第二阶段损失权重1，第一阶段0.5）或更低， 使主要优化目标放在精细输出。同时监控第一阶段输出质量，若发现第一阶段输出退化严重，可增大$
\lambda$适当监督其保持合理结果。对于不同任务可以调整损失函数： - 去噪等像素精确任务：以MSE/L1为主 损失即可。 - 超分辨率、去雨等可能加入感知损失（如LPIPS）提高视觉质量。 - 若追求更逼真的细节，可引入 对抗损失（如PatchGAN判别器），不过要平衡训练稳定性。

优化器可采用AdamW（Transformer常用）并配合余弦退火或分段降低学习率策略。权重衰减可设如1e-4防止 过拟合。训练中注意监控第二阶段相对于第一阶段的增益，确保残差编码模块确实在发挥作用。若发现第二阶   段贡献不大，可能需要增大学习率或损失权重给予其更多驱动。
4. 验证与测试： 在验证集计算PSNR/SSIM等指标时，主要关注第二阶段输出。如果第一阶段也有输出，可对比 两阶段性能提升幅度。在CIFAR-10等小图像数据集上测试时，ViT-Base可能偏大，可考虑缩小patch大小或使用 ViT-Lite结构，但原理相同。在ImageNet等较复杂数据上微调，可利用预训练权重加快收敛，并在验证集上调    优超参数。
通过以上方案，预期模型能够借助残差条件模块，在保持DMAE已有重建能力的基础上进一步强化细节恢复和结 构保真。RCOT论文的实验也表明，两阶段残差条件方法在多种恢复任务上取得了更好的结构细节效果 7。综  上，本方案提供了完整的实现思路和代码示例，可用于将DMAE  ViT-Base模型拓展为RCOT风格的残差二阶段恢 复架构，并在实际图像去噪等任务中验证其性能。


1    [2210.06983] Denoising Masked AutoEncoders Help Robust Classification https://arxiv.org/abs/2210.06983
2    7    Residual-Conditioned Optimal Transport Towards(2).pdf
file://file-Eau2eCFvV4yamdn5rjYeX2
3   4   5   6    Residual-Conditioned Optimal Transport: Towards Structure-Preserving Unpaired and Paired Image Restoration
https://arxiv.org/html/2405.02843v1